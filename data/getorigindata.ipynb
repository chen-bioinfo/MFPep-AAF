{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 读取 .npy 文件\n",
    "train_data = np.load('/geniusland/home/huangjinpeng/MyModel/data/train_data/train_data.npy',allow_pickle=True).tolist()  # 替换为你的文件路径\n",
    "test_data = np.load('/geniusland/home/huangjinpeng/MyModel/data/test_data/test_data.npy',allow_pickle=True).tolist()  # 替换为你的文件路径\n",
    "data0 = np.load('/geniusland/home/huangjinpeng/MyModel/data/train_data/train_seq_name_dict.npy',allow_pickle=True).tolist()  # 替换为你的文件路径\n",
    "data1=np.load('/geniusland/home/huangjinpeng/MyModel/data/test_data/test_seq_name_dict.npy',allow_pickle=True).tolist()  # 替换为你的文件路径\n",
    "data=np.load('/geniusland/home/huangjinpeng/MyModel/data/all_data.npy',allow_pickle=True).tolist()  \n",
    "# 查看数据内容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import json\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from collections import defaultdict\n",
    "# print(len(train_data))\n",
    "# print(train_data)\n",
    "fasta_file= '/geniusland/home/huangjinpeng/MyModel/data/origin_test_data1/test.fasta'\n",
    "seq_train = {}\n",
    "i=0\n",
    "with open(fasta_file) as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        fasta_id = record.seq\n",
    "        # print(fasta_id)\n",
    "        seq_train[record.seq] = record.id\n",
    "        if len(record.seq)>100:\n",
    "            i+=1\n",
    "# dest={}\n",
    "# for key,value in seq_train.items():\n",
    "#     dest[seq_train[key]] = test_data[key].tolist()\n",
    "#     # print(dest)\n",
    "# print(len(dest))\n",
    "# with open(\"/geniusland/home/huangjinpeng/MyModel/gearnet/MFBPtest.json\", 'w') as f:\n",
    "#     json.dump(dest, f)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "fasta_file= '/geniusland/home/huangjinpeng/MyModel/data/test_data/test.fasta'\n",
    "seq_train = set()\n",
    "with open(fasta_file) as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        fasta_id = record.seq\n",
    "        # print(fasta_id)\n",
    "        seq_train.add(fasta_id)\n",
    "missdict={}\n",
    "for seq,id in test_data.items():\n",
    "    if seq not in seq_train:\n",
    "        missdict[seq]=id\n",
    "print(missdict)\n",
    "print(len(missdict))\n",
    "i=0\n",
    "with open(\"/geniusland/home/huangjinpeng/MyModel/data/origin_test1.fasta\", \"a\") as f:\n",
    "    for seq,id in missdict.items():\n",
    "        f.write(f\">extra_{i}\\n\")\n",
    "        f.write(f\"{seq}\\n\")\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Bio import SeqIO\n",
    "# 读取 pkl 文件\n",
    "with open('/geniusland/home/huangjinpeng/MyModel/data/train_data/train_data_list1.pkl', 'rb') as f:  # 注意必须是 'rb' 二进制模式\n",
    "    train_data_list = pickle.load(f)\n",
    "\n",
    "with open('/geniusland/home/huangjinpeng/MyModel/data/test_data/test_data_list1.pkl', 'rb') as f:  # 注意必须是 'rb' 二进制模式\n",
    "    test_data_list = pickle.load(f)\n",
    "\n",
    "print(len(train_data_list))\n",
    "print(len(test_data_list))\n",
    "print(train_data_list[0].x.shape,test_data_list[0].x.shape)\n",
    "fasta_file= '/geniusland/home/huangjinpeng/MyModel/data/origin_test_data1/test.fasta'\n",
    "origin_test = []\n",
    "k=0\n",
    "with open(fasta_file) as handle:\n",
    "    i=0\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        fasta_id = record.seq\n",
    "        if i<len(test_data_list):\n",
    "            if fasta_id!=test_data_list[i].seq:\n",
    "                print(fasta_id)\n",
    "                print(test_data_list[i])\n",
    "                exit(0)\n",
    "            origin_test.append(test_data_list[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            check_seq=fasta_id\n",
    "            for j in range(len(train_data_list)):\n",
    "                if fasta_id==train_data_list[j].seq:\n",
    "                    # print(fasta_id)\n",
    "                    # print(train_data_list[j].seq)\n",
    "                    # print(f\"匹配成功{i}\")\n",
    "                    k+=1\n",
    "                    origin_test.append(train_data_list[j])\n",
    "            i+=1\n",
    "print(len(origin_test))\n",
    "print(k)\n",
    "with open(\"/geniusland/home/huangjinpeng/MyModel/data/origin_test_data1/test_data_list1.pkl\", \"wb\") as f:\n",
    "            pickle.dump(origin_test, f)\n",
    "\n",
    "with open(\"/geniusland/home/huangjinpeng/MyModel/data/origin_test_data1/test_data_list1.pkl\", \"rb\") as f:\n",
    "            tt=pickle.load(f)\n",
    "print(len(tt))\n",
    "with open(fasta_file) as handle:\n",
    "    i=0\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            fasta_id = record.seq\n",
    "            if i<len(tt):\n",
    "                if fasta_id!=tt[i].seq:\n",
    "                    print(fasta_id)\n",
    "                    print(tt[i])\n",
    "                    print(f\"不匹配成功{i}\")\n",
    "                    exit(0)\n",
    "                i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Bio import SeqIO\n",
    "# 读取 pkl 文件\n",
    "with open('/geniusland/home/huangjinpeng/MyModel/data/train_data/train_data_list1.pkl', 'rb') as f:  # 注意必须是 'rb' 二进制模式\n",
    "    train_data_list = pickle.load(f)\n",
    "\n",
    "with open('/geniusland/home/huangjinpeng/MyModel/data/test_data/test_data_list1.pkl', 'rb') as f:  # 注意必须是 'rb' 二进制模式\n",
    "    test_data_list = pickle.load(f)\n",
    "\n",
    "print(len(train_data_list))\n",
    "print(len(test_data_list))\n",
    "print(train_data_list[0].x.shape,test_data_list[0].x.shape)\n",
    "fasta_file= '/geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/train.fasta'\n",
    "origin_test = []\n",
    "k=0\n",
    "with open(fasta_file) as handle:\n",
    "    i=0\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        fasta_id = record.seq\n",
    "        if i<len(train_data_list):\n",
    "            if fasta_id!=train_data_list[i].seq:\n",
    "                print(fasta_id)\n",
    "                print(train_data_list[i])\n",
    "                exit(0)\n",
    "            origin_test.append(train_data_list[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            check_seq=fasta_id\n",
    "            for j in range(len(test_data_list)):\n",
    "                if fasta_id==test_data_list[j].seq:\n",
    "                    # print(fasta_id)\n",
    "                    # print(train_data_list[j].seq)\n",
    "                    # print(f\"匹配成功{i}\")\n",
    "                    k+=1\n",
    "                    origin_test.append(test_data_list[j])\n",
    "            i+=1\n",
    "print(len(origin_test))\n",
    "print(k)\n",
    "with open(\"/geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/train_data_list1.pkl\", \"wb\") as f:\n",
    "            pickle.dump(origin_test, f)\n",
    "\n",
    "with open(\"/geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/train_data_list1.pkl\", \"rb\") as f:\n",
    "            tt=pickle.load(f)\n",
    "print(len(tt))\n",
    "with open(fasta_file) as handle:\n",
    "    i=0\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            fasta_id = record.seq\n",
    "            if i<len(tt):\n",
    "                if fasta_id!=tt[i].seq:\n",
    "                    print(fasta_id)\n",
    "                    print(tt[i])\n",
    "                    print(f\"不匹配成功{i}\")\n",
    "                    exit(0)\n",
    "                i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "with open(\"origin_test.fasta\", \"w\") as f:\n",
    "    for seq, label in test_data.items():\n",
    "        if seq in data1:  # 确保序列在id字典中存在\n",
    "            seq_id = data1[seq]\n",
    "            # 写入FASTA格式\n",
    "            f.write(f\">{seq_id}\\n\")\n",
    "            f.write(f\"{seq}\\n\")\n",
    "        # elif seq in data0:\n",
    "        #     seq_id = data0[seq]\n",
    "        #     # 写入FASTA格式\n",
    "        #     if seq_id =='278_ACP_AMP':\n",
    "        #         f.write(f\">{'279_ACP_AMP'}\\n\")\n",
    "        #         f.write(f\"{seq}\\n\")\n",
    "        #     else:\n",
    "        #         f.write(f\">{seq_id}\\n\")\n",
    "        #         f.write(f\"{seq}\\n\")\n",
    "        else:\n",
    "            count+=1\n",
    "            print(f\"警告: 序列 '{seq}' 在id字典中未找到对应ID\")\n",
    "print(count)\n",
    "print(\"FASTA文件已生成: output.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from Bio import SeqIO\n",
    "\n",
    "def copy_npz_by_fasta_ids(fasta_file, src_folder, src_folder1,dest_folder):\n",
    "    \"\"\"\n",
    "    遍历FASTA文件中的每个ID，查找对应的npz文件并复制到新文件夹\n",
    "    \n",
    "    参数:\n",
    "        fasta_file: 输入的FASTA文件路径\n",
    "        src_folder: 包含npz文件的源文件夹\n",
    "        dest_folder: 目标文件夹（将复制匹配的文件到这里）\n",
    "    \"\"\"\n",
    "    # 创建目标文件夹（如果不存在）\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    \n",
    "    # 统计变量\n",
    "    total_ids = 0\n",
    "    copied_files = 0\n",
    "    missing_ids = []\n",
    "    \n",
    "    # 遍历FASTA文件中的每个记录\n",
    "    with open(fasta_file) as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            total_ids += 1\n",
    "            # 假设FASTA头格式为\">1_AMP\"，提取ID部分\"1\"\n",
    "            fasta_id = record.id\n",
    "            npz_filename = f\"{fasta_id}.npz\"\n",
    "            src_path = os.path.join(src_folder, npz_filename)\n",
    "            src_path1 = os.path.join(src_folder1, npz_filename)\n",
    "            # 检查npz文件是否存在\n",
    "            if os.path.exists(src_path):\n",
    "                dest_path = os.path.join(dest_folder, npz_filename)\n",
    "                shutil.copy2(src_path, dest_path)\n",
    "                copied_files += 1\n",
    "            elif os.path.exists(src_path1) and fasta_id!='278_ACP_AMP':\n",
    "                dest_path = os.path.join(dest_folder, npz_filename)\n",
    "                shutil.copy2(src_path1, dest_path)\n",
    "                copied_files += 1\n",
    "            elif fasta_id=='279_ACP_AMP':\n",
    "                dest_path = os.path.join(dest_folder, '279_ACP_AMP.hhm')\n",
    "                src_path1 = os.path.join(src_folder1, '278_ACP_AMP.hhm')\n",
    "                shutil.copy2(src_path1, dest_path)\n",
    "                copied_files += 1\n",
    "            else:\n",
    "                missing_ids.append(fasta_id)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"FASTA文件中的总ID数量: {total_ids}\")\n",
    "    print(f\"成功复制的npz文件数量: {copied_files}\")\n",
    "    \n",
    "    # 报告缺失的文件\n",
    "    if missing_ids:\n",
    "        print(f\"\\n未找到以下ID对应的npz文件 (共{len(missing_ids)}个):\")\n",
    "        for id in missing_ids[:10]:  # 最多显示前10个缺失ID\n",
    "            print(id)\n",
    "        if len(missing_ids) > 10:\n",
    "            print(f\"...(仅显示前10个，共{len(missing_ids)}个未找到)\")\n",
    "\n",
    "# 使用示例\n",
    "fasta_file = \"/geniusland/home/huangjinpeng/MyModel/data/origin_test_data/test.fasta\"       # 你的FASTA文件路径\n",
    "src_folder = \"/geniusland/home/huangjinpeng/MyModel/data/train_data/npz\"\n",
    "src_folder1 = \"/geniusland/home/huangjinpeng/MyModel/data/test_data/npz\"     # 原始npz文件文件夹\n",
    "dest_folder = \"/geniusland/home/huangjinpeng/MyModel/data/origin_test_data//npz\"   # 新文件夹路径\n",
    "\n",
    "copy_npz_by_fasta_ids(fasta_file, src_folder1, src_folder,dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Copied: 77_ACP_AMP.npz -> extra_0.npz\n",
      "1\n",
      "Copied: 291_ACP_AMP.npz -> extra_1.npz\n",
      "1\n",
      "Copied: 1072_ACP_AMP.npz -> extra_2.npz\n",
      "1\n",
      "Copied: 1137_ACP_AMP.npz -> extra_3.npz\n",
      "1\n",
      "Copied: 747_ACP_AMP.npz -> extra_4.npz\n",
      "1\n",
      "Copied: 278_ACP_AMP.npz -> extra_5.npz\n",
      "1\n",
      "Copied: 659_ADP_AIP.npz -> extra_6.npz\n",
      "1\n",
      "Copied: 1025_ACP_AMP.npz -> extra_7.npz\n",
      "1\n",
      "Copied: 1019_ACP_AMP.npz -> extra_8.npz\n",
      "1\n",
      "Copied: 231_ADP_AIP.npz -> extra_9.npz\n",
      "1\n",
      "Copied: 1094_ACP_AMP.npz -> extra_10.npz\n",
      "1\n",
      "Copied: 367_ADP_AIP.npz -> extra_11.npz\n",
      "1\n",
      "Copied: 827_ACP_AMP.npz -> extra_12.npz\n",
      "1\n",
      "Copied: 738_ACP_AMP.npz -> extra_13.npz\n",
      "\n",
      "Operation complete. Copied 14/14 PDB files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from Bio import SeqIO\n",
    "\n",
    "# 配置路径 (根据实际情况修改)\n",
    "ref_fasta = \"/geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/train.fasta\"      # 第一个FASTA文件（含extra_开头的ID）\n",
    "src_fasta = \"/geniusland/home/huangjinpeng/MyModel/data/test_data/test.fasta\"     # 第二个FASTA文件（含PDB对应的ID）\n",
    "pdb_dir = \"/geniusland/home/huangjinpeng/MyModel/data/test_data/npz\"         # PDB文件所在目录\n",
    "output_dir = \"/geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/npz\"    # 新PDB文件保存目录\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 步骤1：读取参考FASTA中的extra序列\n",
    "extra_seqs = {}\n",
    "for record in SeqIO.parse(ref_fasta, \"fasta\"):\n",
    "    if record.id.startswith(\"extra_\"):\n",
    "        # 去除序列中的空白并转为大写\n",
    "        clean_seq = str(record.seq).replace(\" \", \"\").upper()\n",
    "        extra_seqs[clean_seq] = record.id\n",
    "\n",
    "# 步骤2：读取源FASTA并建立序列到ID的映射\n",
    "seq_to_src_ids = {}\n",
    "for record in SeqIO.parse(src_fasta, \"fasta\"):\n",
    "    clean_seq = str(record.seq).replace(\" \", \"\").upper()\n",
    "    if clean_seq not in seq_to_src_ids:\n",
    "        seq_to_src_ids[clean_seq] = []\n",
    "    seq_to_src_ids[clean_seq].append(record.id)\n",
    "\n",
    "# 步骤3：匹配序列并复制PDB文件\n",
    "copied_count = 0\n",
    "for seq, extra_id in extra_seqs.items():\n",
    "    if seq in seq_to_src_ids:\n",
    "        print(len(seq_to_src_ids[seq]))\n",
    "        for src_id in seq_to_src_ids[seq]:\n",
    "            src_pdb = os.path.join(pdb_dir, f\"{src_id}.npz\")\n",
    "            if os.path.exists(src_pdb):\n",
    "                dest_pdb = os.path.join(output_dir, f\"{extra_id}.npz\")\n",
    "                shutil.copy2(src_pdb, dest_pdb)\n",
    "                print(f\"Copied: {src_id}.npz -> {extra_id}.npz\")\n",
    "                copied_count += 1\n",
    "                break  # 找到一个匹配即停止\n",
    "            else:\n",
    "                print(f\"! PDB not found for {extra_id} (sequence matched but no PDB)\")\n",
    "    else:\n",
    "        print(f\"! Sequence not found for {extra_id}\")\n",
    "\n",
    "print(f\"\\nOperation complete. Copied {copied_count}/{len(extra_seqs)} PDB files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from Bio import SeqIO\n",
    "\n",
    "# 配置路径 (根据实际情况修改)\n",
    "ref_fasta = \"/geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/train.fasta\"      # 第一个FASTA文件（含extra_开头的ID）\n",
    "src_fasta = \"/geniusland/home/huangjinpeng/MyModel/data/test_data/test.fasta\"     # 第二个FASTA文件（含PDB对应的ID）\n",
    "pdb_dir = \"/geniusland/home/huangjinpeng/MyModel/data/test_data/pdb\"         # PDB文件所在目录\n",
    "output_dir = \"/geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/pdb\"    # 新PDB文件保存目录\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 步骤1：读取参考FASTA中的extra序列\n",
    "extra_seqs = {}\n",
    "i=0\n",
    "for record in SeqIO.parse(ref_fasta, \"fasta\"):\n",
    "    if record.id.startswith(\"extra_\"):\n",
    "        # 去除序列中的空白并转为大写\n",
    "        clean_seq = str(record.seq).replace(\" \", \"\").upper()\n",
    "        extra_seqs[clean_seq] = record.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目录: /geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/hhm/output\n",
      "总文件数: 4763\n",
      "以.pdb结尾的文件数: 4763\n",
      "其他文件数: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def count_files(directory):\n",
    "    \"\"\"统计文件夹中的文件数量\"\"\"\n",
    "    total_files = 0\n",
    "    pdb_files = 0\n",
    "    \n",
    "    # 遍历目录中的所有条目\n",
    "    for entry in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, entry)\n",
    "        \n",
    "        # 只统计文件，忽略目录\n",
    "        if os.path.isfile(full_path):\n",
    "            total_files += 1\n",
    "            \n",
    "            # 检查是否以.pdb结尾\n",
    "            if entry.lower().endswith('.hhm'):\n",
    "                pdb_files += 1\n",
    "    \n",
    "    return total_files, pdb_files\n",
    "\n",
    "def main():\n",
    "    # 获取要统计的目录路径\n",
    "    directory = \"/geniusland/home/huangjinpeng/MyModel/data/origin_train_data1/hhm/output\"\n",
    "    \n",
    "    # 检查目录是否存在\n",
    "    if not os.path.isdir(directory):\n",
    "        print(f\"错误：目录 '{directory}' 不存在\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # 统计文件\n",
    "    total, pdb = count_files(directory)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"目录: {directory}\")\n",
    "    print(f\"总文件数: {total}\")\n",
    "    print(f\"以.pdb结尾的文件数: {pdb}\")\n",
    "    print(f\"其他文件数: {total - pdb}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SaProt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
